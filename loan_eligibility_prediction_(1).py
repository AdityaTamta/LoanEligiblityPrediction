# -*- coding: utf-8 -*-
"""Loan_Eligibility_Prediction (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f1U2wnZbxgmSIRLXoUIwFOeC_x5TRYmI
"""

import pandas as pd
import numpy as np
from sklearn import svm
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.applications import VGG19
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

df = pd.read_csv("loan.csv")

df.head()

df.info()

df.isnull().sum()

df['loanAmount_log']=np.log(df['LoanAmount'])
df['loanAmount_log'].hist(bins=20)

df.isnull().sum()

df['TotalIncome']=df['ApplicantIncome']+df['CoapplicantIncome']
df['TotalIncome_log']=np.log(df['TotalIncome'])
df['TotalIncome_log'].hist(bins=20)

df['Gender'].fillna(df['Gender'].mode()[0], inplace = True)
  df['Married'].fillna(df['Married'].mode()[0], inplace = True)
  df['Self_Employed'].fillna(df['Self_Employed'].mode()[0], inplace = True)
  df['Dependents'].fillna(df['Dependents'].mode()[0], inplace = True)
  df.LoanAmount=df.LoanAmount.fillna(df.LoanAmount.mean())
  df.loanAmount_log=df.loanAmount_log.fillna(df.loanAmount_log.mean())
  df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mode()[0], inplace = True)
  df['Credit_History'].fillna(df['Credit_History'].mode()[0], inplace = True)
  df.isnull().sum()

x=df.iloc[:,np.r_[1:5,9:11,13:15]].values
y=df.iloc[:,12].values
x

y

print("percent of missing gender is  %2f%%"%((df['Gender'].isnull().sum()/df.shape[0])*100))

print("number of people who take loan as groupwise gender:")
print(df['Gender'].value_counts())
sns.countplot(x='Gender',data=df,palette='Set1')

print("number of people who take loan as marital status:")
print(df['Married'].value_counts())
sns.countplot(x='Married',data=df,palette='Set1')

print("number of people who take loan as dependents:")
print(df['Dependents'].value_counts())
sns.countplot(x='Dependents',data=df,palette='Set1')

print("number of people who take loan as Self Employed:")
print(df['Self_Employed'].value_counts())
sns.countplot(x='Self_Employed',data=df,palette='Set1')

print("number of people who take loan as LoanAmount:")
print(df['LoanAmount'].value_counts())
sns.countplot(x='LoanAmount',data=df,palette='Set1')

print("number of people who take loan as Credit History:")
print(df['Credit_History'].value_counts())
sns.countplot(x='Credit_History',data=df,palette='Set1')

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test= train_test_split(x,y,test_size=0.2,random_state=0)
from sklearn.preprocessing import LabelEncoder
Labelencoder_x = LabelEncoder()

for i in range(0,5):
  X_train[:,i] = Labelencoder_x.fit_transform(X_train[:,i])
  X_train[:,7] = Labelencoder_x.fit_transform(X_train[:,7])
X_train

Labelencoder_y = LabelEncoder()
y_train=Labelencoder_y.fit_transform(y_train)
y_train

for i in range(0,5):
  X_test[:,i]=Labelencoder_x.fit_transform(X_test[:,i])
  X_test[:,7]=Labelencoder_x.fit_transform(X_test[:,7])
X_test

Labelencoder_y=LabelEncoder()
y_test=Labelencoder_y.fit_transform(y_test)
y_test

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
X_train = ss.fit_transform(X_train)
x_test = ss.fit_transform(X_test)

from sklearn.ensemble import RandomForestClassifier
rf_clf = RandomForestClassifier()
rf_clf.fit(X_train,y_train)

from sklearn import metrics
y_pred = rf_clf.predict(x_test)
print("acc of random forest clf is", metrics.accuracy_score(y_pred,y_test))

from sklearn.naive_bayes import GaussianNB
nb_clf = GaussianNB()
nb_clf.fit(X_train,y_train)

y_pred = nb_clf.predict(x_test)
print("acc of naive bayes clf is", metrics.accuracy_score(y_pred,y_test))

y_pred

from sklearn.tree import DecisionTreeClassifier
dt_clf = DecisionTreeClassifier()
dt_clf.fit(X_train,y_train)

y_pred = dt_clf.predict(x_test)
print("acc of decision tree clf is", metrics.accuracy_score(y_pred,y_test))

y_pred

from sklearn.neighbors import KNeighborsClassifier
knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train,y_train)

y_pred = knn_clf.predict(x_test)
print("acc of Kneighbors clf is", metrics.accuracy_score(y_pred,y_test))

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# Define the neural network model
model = Sequential([
    Dense(64, input_dim=X_train.shape[1], activation='relu'),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(1, activation='sigmoid')  # Binary classification
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Convert X_train and y_train to float32
X_train = X_train.astype('float32')
y_train = y_train.astype('float32')
X_test = X_test.astype('float32')
y_test = y_test.astype('float32')


# Train the model
history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32, verbose=1)

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {accuracy * 100:.2f}%")